{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Start!\n",
    "\n",
    "## Problem:\n",
    "Mamy doczynienia z serią danych numerycznych wraz z problemem klasyfikacji binarnej.\n",
    "\n",
    "Na podstawie opisów cech można wywnioskować, że są one w jakimś stopniu ze sobą powiązane - chociażby szerokość serca czy płuc z ich polem powierzchni.\n",
    "\n",
    "### Moja początkowa intuicja:\n",
    "1. Dokonać analizy PCA na cechach, by ograniczyć szum informacji\n",
    "2. Zastosować klasyfikację knn z cross-examination na hiperparametrze k, by uniknąć under lub overfittingu\n",
    "\n"
   ],
   "id": "de37de0f9d9941b0"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-26T14:16:34.960003Z",
     "start_time": "2025-10-26T14:16:34.957136Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.classify.svm import SvmClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ],
   "outputs": [],
   "execution_count": 121
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T14:16:34.986929Z",
     "start_time": "2025-10-26T14:16:34.980215Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load DataFrame from CSV\n",
    "df = pd.read_csv(\"task_data.csv\", sep=\",\")\n",
    "\n",
    "# Fix commas in floats (if necessary)\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == object:\n",
    "        df[col] = df[col].str.replace(\",\", \".\")\n",
    "\n",
    "# Convert columns except 'ID' and label to float\n",
    "cols_to_float = [col for col in df.columns if col not in ['ID', 'Cardiomegaly']]\n",
    "df[cols_to_float] = df[cols_to_float].astype(float)\n",
    "\n",
    "# Encode target labels if necessary\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df[\"Cardiomegaly\"])\n",
    "X = df.drop(columns=[\"ID\", \"Cardiomegaly\"]).values\n"
   ],
   "id": "bb42823626f085bb",
   "outputs": [],
   "execution_count": 122
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T14:16:35.070630Z",
     "start_time": "2025-10-26T14:16:35.003679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(sampling_strategy='auto')\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "print(y_resampled.shape)\n"
   ],
   "id": "d7911964fb7d8b89",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/grzegorzprywatny/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 123
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T14:16:35.140050Z",
     "start_time": "2025-10-26T14:16:35.103467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_standardized = scaler.fit_transform(X_resampled)\n",
    "\n",
    "# Zdecydowałem się nie używać PCA\n",
    "X_reduced = X_standardized\n"
   ],
   "id": "d41f8d6ac4555bb7",
   "outputs": [],
   "execution_count": 124
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T14:16:46.364416Z",
     "start_time": "2025-10-26T14:16:35.168231Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'max_depth': [None, 10, 20, 50, 100, 200],\n",
    "    'min_samples_split': [2, 5 ],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "}\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y_resampled)\n",
    "rfClassifier = RandomForestClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rfClassifier,\n",
    "    param_grid=param_grid,\n",
    "    cv=2,\n",
    "    n_jobs=-1,\n",
    "    scoring='roc_auc'\n",
    "    )\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.predict([X_test[0]]))\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Estimator:\", grid_search.best_estimator_)\n",
    "print(\"Accuracy:\", grid_search.score(X_test, y_test))\n",
    "\n",
    "rfClassifier = grid_search.best_estimator_\n"
   ],
   "id": "7fa04e88ec8a308e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "Best Parameters: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best Estimator: RandomForestClassifier(n_estimators=200)\n",
      "Accuracy: 0.9333333333333333\n"
     ]
    }
   ],
   "execution_count": 125
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T14:16:46.573889Z",
     "start_time": "2025-10-26T14:16:46.379649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "   \"n_neighbors\": range(1, 11),\n",
    "    \"leaf_size\": range(30,200,5),\n",
    "    \"weights\": [\"uniform\", \"distance\"]\n",
    "}\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y_resampled)\n",
    "knClassifier = KNeighborsClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=knClassifier,\n",
    "    param_grid=param_grid,\n",
    "    cv=2,\n",
    "    n_jobs=-1,\n",
    "    scoring='roc_auc'\n",
    "    )\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Estimator:\", grid_search.best_estimator_)\n",
    "print(\"Accuracy:\", grid_search.score(X_test, y_test))\n",
    "\n",
    "knClassifier = grid_search.best_estimator_\n",
    "\n"
   ],
   "id": "697dd3efb3095c3d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'leaf_size': 30, 'n_neighbors': 8, 'weights': 'distance'}\n",
      "Best Estimator: KNeighborsClassifier(n_neighbors=8, weights='distance')\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "execution_count": 126
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T14:16:46.607842Z",
     "start_time": "2025-10-26T14:16:46.589303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\"],\n",
    "}\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y_resampled)\n",
    "logisticRegression = LogisticRegression(max_iter=10000)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=logisticRegression,\n",
    "    param_grid=param_grid,\n",
    "    cv=2,\n",
    "    n_jobs=-1,\n",
    "    scoring='roc_auc'\n",
    "    )\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.predict([X_test[0]]), y_test[0])\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Estimator:\", grid_search.best_estimator_)\n",
    "print(\"Accuracy:\", grid_search.score(X_test, y_test))\n",
    "\n",
    "logisticRegression = grid_search.best_estimator_\n",
    "\n"
   ],
   "id": "e7269ea0515289a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] 1\n",
      "Best Parameters: {'solver': 'newton-cg'}\n",
      "Best Estimator: LogisticRegression(max_iter=10000, solver='newton-cg')\n",
      "Accuracy: 0.8541666666666667\n"
     ]
    }
   ],
   "execution_count": 127
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T14:16:46.612314Z",
     "start_time": "2025-10-26T14:16:46.610259Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def predict(samples):\n",
    "    results = []\n",
    "    results.append([x[1] for x in logisticRegression.predict_proba(samples)])\n",
    "    results.append(knClassifier.predict(samples))\n",
    "    results.append(rfClassifier.predict(samples))\n",
    "\n",
    "    # Korzystamy ze średniej tych modeli\n",
    "    sum_of_results = np.sum(results, axis=0)/3\n",
    "\n",
    "    sum_of_results = np.round(sum_of_results, decimals=0)\n",
    "    return sum_of_results"
   ],
   "id": "bbd2b080e78b0b62",
   "outputs": [],
   "execution_count": 128
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T14:17:21.847979Z",
     "start_time": "2025-10-26T14:17:21.835563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# As data is split randomly, for our last test let's split it again\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y_resampled)\n",
    "\n",
    "predictions = predict(X_test)\n",
    "actual = y_test\n",
    "\n",
    "accuracy = accuracy_score(actual, predictions)\n",
    "precision = precision_score(actual, predictions)\n",
    "recall = recall_score(actual, predictions)\n",
    "f1 = f1_score(actual, predictions)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ],
   "id": "973c96b71eb13bb4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1-score: 1.0\n"
     ]
    }
   ],
   "execution_count": 136
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T14:16:46.672836Z",
     "start_time": "2025-10-26T14:16:46.671707Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "38ea575d80c0cb6f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Start!\n",
    "\n",
    "## Problem:\n",
    "Mamy doczynienia z serią danych numerycznych wraz z problemem klasyfikacji binarnej.\n",
    "\n",
    "Na podstawie opisów cech można wywnioskować, że są one w jakimś stopniu ze sobą powiązane - chociażby szerokość serca czy płuc z ich polem powierzchni.\n",
    "\n",
    "### Moja początkowa intuicja:\n",
    "1. Dokonać analizy PCA na cechach, by ograniczyć szum informacji\n",
    "2. Zastosować klasyfikację knn z cross-examination na hiperparametrze k, by uniknąć under lub overfittingu"
   ],
   "id": "de37de0f9d9941b0"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-27T17:21:30.065920Z",
     "start_time": "2025-10-27T17:21:30.063239Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T17:21:30.093721Z",
     "start_time": "2025-10-27T17:21:30.087750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load DataFrame from CSV\n",
    "df = pd.read_csv(\"task_data.csv\", sep=\",\")\n",
    "\n",
    "# Fix commas in floats (if necessary)\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == object:\n",
    "        df[col] = df[col].str.replace(\",\", \".\")\n",
    "\n",
    "# Convert columns except 'ID' and label to float\n",
    "cols_to_float = [col for col in df.columns if col not in ['ID', 'Cardiomegaly']]\n",
    "df[cols_to_float] = df[cols_to_float].astype(float)\n",
    "\n",
    "# Encode target labels if necessary\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df[\"Cardiomegaly\"])\n",
    "X = df.drop(columns=[\"ID\", \"Cardiomegaly\"]).values\n"
   ],
   "id": "bb42823626f085bb",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Dataset jest niezbalansowany. Zdecydowałem się skorzystać z techniki SMOTE.\n",
    "\n",
    "Poza tym, jako że ten dataset to pomiary, postanowiłem rozszerzyć go o dane z nałożonym szumem, zwiększając tym samym rozmiar datasetu i osiągając lepsze wyniki w modelach"
   ],
   "id": "8c551f489b26a1dc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T17:21:30.114729Z",
     "start_time": "2025-10-27T17:21:30.110777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(sampling_strategy='auto')\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# adding noisy data:\n",
    "noise_level = 0.045\n",
    "\n",
    "feature_stds = np.std(X_resampled, axis=0)\n",
    "\n",
    "noise = np.random.normal(loc=0, scale=noise_level * feature_stds, size=X_resampled.shape)\n",
    "\n",
    "X_noisy = X_resampled + noise\n",
    "\n",
    "X_resampled = np.array([*X_resampled, *X_noisy])\n",
    "y_resampled = np.array([*y_resampled, *y_resampled])\n",
    "\n",
    "print(y_resampled.shape)\n"
   ],
   "id": "d7911964fb7d8b89",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/grzegorzprywatny/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Standaryzacja danych przed przepuszczeniem przez model",
   "id": "b6a8fbfe5cbc8fa0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T17:21:30.121185Z",
     "start_time": "2025-10-27T17:21:30.118775Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_standardized = scaler.fit_transform(X_resampled)\n",
    "\n",
    "X_reduced = X_standardized\n"
   ],
   "id": "d41f8d6ac4555bb7",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Podział na dane testowe i treningowe",
   "id": "41bfe4b0317cda10"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T17:21:30.149684Z",
     "start_time": "2025-10-27T17:21:30.147770Z"
    }
   },
   "cell_type": "code",
   "source": "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y_resampled)",
   "id": "bfb64f99d3dc9d67",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Dobór modeli\n",
    "Do problemu klasyfikacji binarnej z niewielką ilością cech numerycznych dobrze nadają się m. in.:\n",
    "- Random Forest Classifier\n",
    "- KNeighbours Classifier\n",
    "- Logistic Regression"
   ],
   "id": "5d18ffc8539db697"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Tutaj dobieram najoptymalniejsze parametry do RFC",
   "id": "6e491e40c4f5d18"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T17:21:41.321285Z",
     "start_time": "2025-10-27T17:21:30.165452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'max_depth': [None, 10, 20, 50, 100, 200],\n",
    "    'min_samples_split': [2, 5 ],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "}\n",
    "\n",
    "rfClassifier = RandomForestClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rfClassifier,\n",
    "    param_grid=param_grid,\n",
    "    cv=2,\n",
    "    n_jobs=-1,\n",
    "    scoring='roc_auc'\n",
    "    )\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.predict([X_test[0]]))\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Estimator:\", grid_search.best_estimator_)\n",
    "print(\"Accuracy:\", grid_search.score(X_test, y_test))\n",
    "\n",
    "rfClassifier = grid_search.best_estimator_\n"
   ],
   "id": "7fa04e88ec8a308e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "Best Parameters: {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Best Estimator: RandomForestClassifier(max_depth=10, max_features='log2', min_samples_split=5)\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Tutaj rozważam różne parametry do KNC",
   "id": "ec60b6264b99cc28"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T17:21:41.587602Z",
     "start_time": "2025-10-27T17:21:41.337486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "   \"n_neighbors\": range(1, 11),\n",
    "    \"leaf_size\": range(30,200,5),\n",
    "    \"weights\": [\"uniform\", \"distance\"]\n",
    "}\n",
    "\n",
    "knClassifier = KNeighborsClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=knClassifier,\n",
    "    param_grid=param_grid,\n",
    "    cv=2,\n",
    "    n_jobs=-1,\n",
    "    scoring='roc_auc'\n",
    "    )\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Estimator:\", grid_search.best_estimator_)\n",
    "print(\"Accuracy:\", grid_search.score(X_test, y_test))\n",
    "\n",
    "knClassifier = grid_search.best_estimator_\n",
    "\n"
   ],
   "id": "697dd3efb3095c3d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'leaf_size': 30, 'n_neighbors': 5, 'weights': 'distance'}\n",
      "Best Estimator: KNeighborsClassifier(weights='distance')\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Tutaj dobieram odpowiedni solver do Logistic Regression",
   "id": "ba002fc8f6629079"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T17:21:41.622719Z",
     "start_time": "2025-10-27T17:21:41.603841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\"],\n",
    "}\n",
    "\n",
    "logisticRegression = LogisticRegression(max_iter=10000)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=logisticRegression,\n",
    "    param_grid=param_grid,\n",
    "    cv=2,\n",
    "    n_jobs=-1,\n",
    "    scoring='roc_auc'\n",
    "    )\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Estimator:\", grid_search.best_estimator_)\n",
    "print(\"Accuracy:\", grid_search.score(X_test, y_test))\n",
    "\n",
    "logisticRegression = grid_search.best_estimator_\n",
    "\n"
   ],
   "id": "e7269ea0515289a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'solver': 'newton-cg'}\n",
      "Best Estimator: LogisticRegression(max_iter=10000, solver='newton-cg')\n",
      "Accuracy: 0.875\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Stacking the models together",
   "id": "7753ef63d9f6acb5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T17:21:41.647704Z",
     "start_time": "2025-10-27T17:21:41.640293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pred1 = rfClassifier.predict_proba(X_train)[:, 1]\n",
    "pred2 = knClassifier.predict_proba(X_train)[:, 1]\n",
    "pred3 = logisticRegression.predict_proba(X_train)[:, 1]\n",
    "\n",
    "meta_X = np.column_stack([pred1, pred2, pred3])\n",
    "\n",
    "meta_model = LogisticRegression()\n",
    "meta_model.fit(meta_X, y_train)\n",
    "\n",
    "def predict(samples):\n",
    "    pred1 = rfClassifier.predict_proba(samples)[:, 1]\n",
    "    pred2 = knClassifier.predict_proba(samples)[:, 1]\n",
    "    pred3 = logisticRegression.predict_proba(samples)[:, 1]\n",
    "    meta_X = np.column_stack([pred1, pred2, pred3])\n",
    "    return meta_model.predict(meta_X)\n"
   ],
   "id": "bbd2b080e78b0b62",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T17:21:41.663054Z",
     "start_time": "2025-10-27T17:21:41.653638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# As data is split randomly, for our last test let's split it again\n",
    "\n",
    "predictions = predict(X_test)\n",
    "actual = y_test\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(actual, predictions)\n",
    "precision = precision_score(actual, predictions)\n",
    "recall = recall_score(actual, predictions)\n",
    "f1 = f1_score(actual, predictions)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ],
   "id": "973c96b71eb13bb4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1-score: 1.0\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T17:21:41.690558Z",
     "start_time": "2025-10-27T17:21:41.689398Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f4d1f5705e95e977",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T17:21:41.709253Z",
     "start_time": "2025-10-27T17:21:41.708098Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "bf14f227af41f706",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

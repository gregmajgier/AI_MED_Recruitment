{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Start!\n",
    "\n",
    "## Problem:\n",
    "Mamy doczynienia z serią danych numerycznych wraz z problemem klasyfikacji binarnej.\n",
    "\n",
    "Na podstawie opisów cech można wywnioskować, że są one w jakimś stopniu ze sobą powiązane - chociażby szerokość serca czy płuc z ich polem powierzchni.\n",
    "\n",
    "### Moja początkowa intuicja:\n",
    "1. Dokonać analizy PCA na cechach, by ograniczyć szum informacji\n",
    "2. Zastosować klasyfikację knn z cross-examination na hiperparametrze k, by uniknąć under lub overfittingu\n",
    "\n"
   ],
   "id": "de37de0f9d9941b0"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-26T13:19:46.860128Z",
     "start_time": "2025-10-26T13:19:46.857401Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from nltk.classify.svm import SvmClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ],
   "outputs": [],
   "execution_count": 224
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T13:19:46.882475Z",
     "start_time": "2025-10-26T13:19:46.877119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load DataFrame from CSV\n",
    "df = pd.read_csv(\"task_data.csv\", sep=\",\")\n",
    "\n",
    "# Fix commas in floats (if necessary)\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == object:\n",
    "        df[col] = df[col].str.replace(\",\", \".\")\n",
    "\n",
    "# Convert columns except 'ID' and label to float\n",
    "cols_to_float = [col for col in df.columns if col not in ['ID', 'Cardiomegaly']]\n",
    "df[cols_to_float] = df[cols_to_float].astype(float)\n",
    "\n",
    "# Encode target labels if necessary\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df[\"Cardiomegaly\"])\n",
    "X = df.drop(columns=[\"ID\", \"Cardiomegaly\"]).values\n"
   ],
   "id": "bb42823626f085bb",
   "outputs": [],
   "execution_count": 225
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T13:19:46.903253Z",
     "start_time": "2025-10-26T13:19:46.900114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(sampling_strategy='auto')\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "print(y_resampled.shape)\n"
   ],
   "id": "d7911964fb7d8b89",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/grzegorzprywatny/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 226
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T13:19:46.927504Z",
     "start_time": "2025-10-26T13:19:46.925129Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_standardized = scaler.fit_transform(X_resampled)\n",
    "\n",
    "# Zdecydowałem się nie używać PCA\n",
    "X_reduced = X_standardized\n"
   ],
   "id": "d41f8d6ac4555bb7",
   "outputs": [],
   "execution_count": 227
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T13:19:58.347404Z",
     "start_time": "2025-10-26T13:19:46.943362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'max_depth': [None, 10, 20, 50, 100, 200],\n",
    "    'min_samples_split': [2, 5 ],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "}\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y_resampled, test_size=0.2)\n",
    "rfClassifier = RandomForestClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rfClassifier,\n",
    "    param_grid=param_grid,\n",
    "    cv=2,\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy'\n",
    "    )\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Estimator:\", grid_search.best_estimator_)\n",
    "print(\"Accuracy:\", grid_search.score(X_test, y_test))\n"
   ],
   "id": "7fa04e88ec8a308e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best Estimator: RandomForestClassifier()\n",
      "Accuracy: 0.8333333333333334\n"
     ]
    }
   ],
   "execution_count": 228
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T13:19:58.561272Z",
     "start_time": "2025-10-26T13:19:58.368803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "   \"n_neighbors\": range(1, 11),\n",
    "    \"leaf_size\": range(30,200,5),\n",
    "    \"weights\": [\"uniform\", \"distance\"]\n",
    "}\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y_resampled)\n",
    "knClassifier = KNeighborsClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=knClassifier,\n",
    "    param_grid=param_grid,\n",
    "    cv=2,\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy'\n",
    "    )\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Estimator:\", grid_search.best_estimator_)\n",
    "print(\"Accuracy:\", grid_search.score(X_test, y_test))\n"
   ],
   "id": "697dd3efb3095c3d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'leaf_size': 30, 'n_neighbors': 4, 'weights': 'distance'}\n",
      "Best Estimator: KNeighborsClassifier(n_neighbors=4, weights='distance')\n",
      "Accuracy: 0.8571428571428571\n"
     ]
    }
   ],
   "execution_count": 229
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T13:19:58.596809Z",
     "start_time": "2025-10-26T13:19:58.579362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "   \"penalty\": [\"l1\", \"l2\"],\n",
    "    \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\"],\n",
    "}\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y_resampled)\n",
    "logisticRegression = LogisticRegression(max_iter=10000)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=logisticRegression,\n",
    "    param_grid=param_grid,\n",
    "    cv=2,\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy'\n",
    "    )\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Estimator:\", grid_search.best_estimator_)\n",
    "print(\"Accuracy:\", grid_search.score(X_test, y_test))\n"
   ],
   "id": "e7269ea0515289a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best Estimator: LogisticRegression(max_iter=10000, penalty='l1', solver='liblinear')\n",
      "Accuracy: 0.8571428571428571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/grzegorzprywatny/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "4 fits failed out of a total of 12.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/grzegorzprywatny/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/grzegorzprywatny/Library/Python/3.9/lib/python/site-packages/sklearn/base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/grzegorzprywatny/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py\", line 1193, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/grzegorzprywatny/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py\", line 63, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/grzegorzprywatny/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/grzegorzprywatny/Library/Python/3.9/lib/python/site-packages/sklearn/base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/grzegorzprywatny/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py\", line 1193, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/grzegorzprywatny/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py\", line 63, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/grzegorzprywatny/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.73809524 0.71428571 0.71428571 0.71428571]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 230
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
